"""
í•œêµ­ì–´ OCR ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë° í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ
ì •í™•ë„ 100% ë‹¬ì„±ì„ ìœ„í•œ ì¢…í•© í…ŒìŠ¤íŠ¸
"""

import unittest
import numpy as np
import cv2
import time
import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Any
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from Levenshtein import distance as levenshtein_distance
import logging

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.korean_ocr_engine import UltraKoreanOCR, OCRConfig
from src.deep_learning_enhancer import DeepLearningOCREnhancer
from src.layout_analyzer import SchoolRecordLayoutAnalyzer

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class OCRBenchmark:
    """OCR ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.ocr_engine = UltraKoreanOCR(OCRConfig())
        self.deep_enhancer = DeepLearningOCREnhancer()
        self.layout_analyzer = SchoolRecordLayoutAnalyzer()
        self.results = []
        
    def run_comprehensive_benchmark(self, test_dataset_path: str) -> Dict[str, Any]:
        """
        ì¢…í•© ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
        
        Args:
            test_dataset_path: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê²½ë¡œ
            
        Returns:
            ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
        """
        logger.info("Starting comprehensive benchmark...")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        test_data = self.load_test_dataset(test_dataset_path)
        
        # ê° í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•´ OCR ìˆ˜í–‰
        for item in test_data:
            image_path = item["image_path"]
            ground_truth = item["ground_truth"]
            
            # OCR ì‹¤í–‰ ë° ì‹œê°„ ì¸¡ì •
            start_time = time.time()
            
            # ê¸°ë³¸ OCR
            basic_result = self.ocr_engine.process_image(
                image_path, 
                enable_enhancement=False,
                enable_multi_pass=False
            )
            basic_time = time.time() - start_time
            
            # í–¥ìƒëœ OCR
            enhanced_start = time.time()
            enhanced_result = self.ocr_engine.process_image(
                image_path,
                enable_enhancement=True,
                enable_multi_pass=True
            )
            enhanced_time = time.time() - enhanced_start
            
            # ë”¥ëŸ¬ë‹ í–¥ìƒ ì ìš©
            dl_start = time.time()
            image = cv2.imread(image_path)
            dl_result = self.deep_enhancer.enhance_ocr_result(image, enhanced_result)
            dl_time = time.time() - dl_start
            
            # ê²°ê³¼ í‰ê°€
            evaluation = self.evaluate_result(
                ground_truth,
                basic_result.get("full_text", ""),
                enhanced_result.get("full_text", ""),
                dl_result.get("full_text", "")
            )
            
            # ê²°ê³¼ ì €ì¥
            self.results.append({
                "image": Path(image_path).name,
                "basic_accuracy": evaluation["basic_accuracy"],
                "enhanced_accuracy": evaluation["enhanced_accuracy"],
                "dl_accuracy": evaluation["dl_accuracy"],
                "basic_time": basic_time,
                "enhanced_time": enhanced_time,
                "dl_time": dl_time,
                "character_accuracy": evaluation["character_accuracy"],
                "word_accuracy": evaluation["word_accuracy"],
                "levenshtein_score": evaluation["levenshtein_score"]
            })
            
            logger.info(f"Processed {Path(image_path).name}: "
                       f"DL Accuracy={evaluation['dl_accuracy']:.2%}")
        
        # ì¢…í•© í†µê³„ ê³„ì‚°
        summary = self.calculate_summary_statistics()
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        self.generate_benchmark_report(summary)
        
        return summary
    
    def load_test_dataset(self, dataset_path: str) -> List[Dict]:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œ"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” JSON íŒŒì¼ì´ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¡œë“œ
        # ì—¬ê¸°ì„œëŠ” ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        test_data = []
        
        # ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
        sample_cases = [
            {
                "image_path": "./data/test1.jpg",
                "ground_truth": "í•™ìƒì€ ì„±ì‹¤í•˜ê³  ì±…ì„ê°ì´ ê°•í•˜ë©° í•™ì—…ì— ëŒ€í•œ ì—´ì •ì´ ë›°ì–´ë‚¨"
            },
            {
                "image_path": "./data/test2.jpg",
                "ground_truth": "2í•™ë…„ 1í•™ê¸° êµ­ì–´ ê³¼ëª©ì—ì„œ ìš°ìˆ˜í•œ ì„±ì ì„ ê±°ë‘ì—ˆìœ¼ë©°"
            },
            {
                "image_path": "./data/test3.jpg",
                "ground_truth": "ì°½ì˜ì ì²´í—˜í™œë™ì—ì„œ ë¦¬ë”ì‹­ì„ ë°œíœ˜í•˜ì—¬ ë™ì•„ë¦¬ í™œë™ì„ ì£¼ë„í•¨"
            }
        ]
        
        for case in sample_cases:
            # ì‹¤ì œ ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
            if not os.path.exists(case["image_path"]):
                self.create_dummy_image(case["image_path"], case["ground_truth"])
            
            test_data.append(case)
        
        return test_data
    
    def create_dummy_image(self, image_path: str, text: str):
        """í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±"""
        os.makedirs(os.path.dirname(image_path), exist_ok=True)
        
        # í° ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
        img = np.ones((200, 800, 3), dtype=np.uint8) * 255
        
        # í…ìŠ¤íŠ¸ ì¶”ê°€
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(img, text[:50], (10, 100), font, 0.8, (0, 0, 0), 2)
        
        # ë…¸ì´ì¦ˆ ì¶”ê°€ (ì‹¤ì œ ìŠ¤ìº” ë¬¸ì„œ ì‹œë®¬ë ˆì´ì…˜)
        noise = np.random.randint(0, 50, img.shape, dtype=np.uint8)
        img = cv2.add(img, noise)
        
        cv2.imwrite(image_path, img)
    
    def evaluate_result(self, ground_truth: str, basic: str, 
                       enhanced: str, dl: str) -> Dict[str, float]:
        """OCR ê²°ê³¼ í‰ê°€"""
        def calculate_accuracy(pred: str, truth: str) -> float:
            if not truth:
                return 0.0
            
            # ë¬¸ì ë‹¨ìœ„ ì •í™•ë„
            correct = sum(1 for p, t in zip(pred, truth) if p == t)
            total = max(len(pred), len(truth))
            return correct / total if total > 0 else 0.0
        
        def word_accuracy(pred: str, truth: str) -> float:
            pred_words = pred.split()
            truth_words = truth.split()
            
            if not truth_words:
                return 0.0
            
            correct = sum(1 for p in pred_words if p in truth_words)
            return correct / len(truth_words)
        
        def normalized_levenshtein(s1: str, s2: str) -> float:
            max_len = max(len(s1), len(s2))
            if max_len == 0:
                return 1.0
            return 1 - (levenshtein_distance(s1, s2) / max_len)
        
        return {
            "basic_accuracy": calculate_accuracy(basic, ground_truth),
            "enhanced_accuracy": calculate_accuracy(enhanced, ground_truth),
            "dl_accuracy": calculate_accuracy(dl, ground_truth),
            "character_accuracy": calculate_accuracy(dl, ground_truth),
            "word_accuracy": word_accuracy(dl, ground_truth),
            "levenshtein_score": normalized_levenshtein(dl, ground_truth)
        }
    
    def calculate_summary_statistics(self) -> Dict[str, Any]:
        """ì¢…í•© í†µê³„ ê³„ì‚°"""
        if not self.results:
            return {}
        
        df = pd.DataFrame(self.results)
        
        summary = {
            "total_tests": len(self.results),
            "average_dl_accuracy": df["dl_accuracy"].mean(),
            "min_dl_accuracy": df["dl_accuracy"].min(),
            "max_dl_accuracy": df["dl_accuracy"].max(),
            "std_dl_accuracy": df["dl_accuracy"].std(),
            "average_character_accuracy": df["character_accuracy"].mean(),
            "average_word_accuracy": df["word_accuracy"].mean(),
            "average_levenshtein_score": df["levenshtein_score"].mean(),
            "average_processing_time": df["dl_time"].mean(),
            "improvement_over_basic": (df["dl_accuracy"] - df["basic_accuracy"]).mean(),
            "improvement_over_enhanced": (df["dl_accuracy"] - df["enhanced_accuracy"]).mean(),
            "perfect_accuracy_rate": (df["dl_accuracy"] >= 0.99).mean(),
            "high_accuracy_rate": (df["dl_accuracy"] >= 0.95).mean(),
            "results_dataframe": df
        }
        
        return summary
    
    def generate_benchmark_report(self, summary: Dict[str, Any]):
        """ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸ ìƒì„±"""
        logger.info("\n" + "="*80)
        logger.info("í•œêµ­ì–´ OCR ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸")
        logger.info("="*80)
        
        logger.info(f"\nğŸ“Š ì¢…í•© ì„±ëŠ¥ ì§€í‘œ:")
        logger.info(f"  â€¢ ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {summary['total_tests']}")
        logger.info(f"  â€¢ í‰ê·  ì •í™•ë„: {summary['average_dl_accuracy']:.2%}")
        logger.info(f"  â€¢ ìµœì†Œ ì •í™•ë„: {summary['min_dl_accuracy']:.2%}")
        logger.info(f"  â€¢ ìµœëŒ€ ì •í™•ë„: {summary['max_dl_accuracy']:.2%}")
        logger.info(f"  â€¢ í‘œì¤€í¸ì°¨: {summary['std_dl_accuracy']:.4f}")
        
        logger.info(f"\nğŸ¯ ì„¸ë¶€ ì •í™•ë„:")
        logger.info(f"  â€¢ ë¬¸ì ë‹¨ìœ„ ì •í™•ë„: {summary['average_character_accuracy']:.2%}")
        logger.info(f"  â€¢ ë‹¨ì–´ ë‹¨ìœ„ ì •í™•ë„: {summary['average_word_accuracy']:.2%}")
        logger.info(f"  â€¢ Levenshtein ì ìˆ˜: {summary['average_levenshtein_score']:.2%}")
        
        logger.info(f"\nâš¡ ì„±ëŠ¥ ì§€í‘œ:")
        logger.info(f"  â€¢ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {summary['average_processing_time']:.3f}ì´ˆ")
        logger.info(f"  â€¢ 99% ì´ìƒ ì •í™•ë„ ë‹¬ì„±ë¥ : {summary['perfect_accuracy_rate']:.1%}")
        logger.info(f"  â€¢ 95% ì´ìƒ ì •í™•ë„ ë‹¬ì„±ë¥ : {summary['high_accuracy_rate']:.1%}")
        
        logger.info(f"\nğŸ“ˆ ê°œì„  íš¨ê³¼:")
        logger.info(f"  â€¢ ê¸°ë³¸ ëŒ€ë¹„ ê°œì„ : +{summary['improvement_over_basic']:.2%}")
        logger.info(f"  â€¢ í–¥ìƒ ëŒ€ë¹„ ê°œì„ : +{summary['improvement_over_enhanced']:.2%}")
        
        # ì‹œê°í™” ìƒì„±
        self.create_visualizations(summary)
    
    def create_visualizations(self, summary: Dict[str, Any]):
        """ì„±ëŠ¥ ì‹œê°í™” ìƒì„±"""
        df = summary["results_dataframe"]
        
        # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì •
        plt.style.use('seaborn-v0_8-darkgrid')
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. ì •í™•ë„ ë¹„êµ
        accuracy_cols = ["basic_accuracy", "enhanced_accuracy", "dl_accuracy"]
        df[accuracy_cols].plot(kind='bar', ax=axes[0, 0])
        axes[0, 0].set_title("OCR ë°©ì‹ë³„ ì •í™•ë„ ë¹„êµ")
        axes[0, 0].set_ylabel("ì •í™•ë„")
        axes[0, 0].set_xlabel("í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€")
        axes[0, 0].legend(["ê¸°ë³¸", "í–¥ìƒ", "ë”¥ëŸ¬ë‹"])
        
        # 2. ì²˜ë¦¬ ì‹œê°„ ë¹„êµ
        time_cols = ["basic_time", "enhanced_time", "dl_time"]
        df[time_cols].plot(kind='bar', ax=axes[0, 1])
        axes[0, 1].set_title("OCR ë°©ì‹ë³„ ì²˜ë¦¬ ì‹œê°„")
        axes[0, 1].set_ylabel("ì‹œê°„ (ì´ˆ)")
        axes[0, 1].set_xlabel("í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€")
        axes[0, 1].legend(["ê¸°ë³¸", "í–¥ìƒ", "ë”¥ëŸ¬ë‹"])
        
        # 3. ì •í™•ë„ ë¶„í¬
        axes[1, 0].hist(df["dl_accuracy"], bins=20, edgecolor='black')
        axes[1, 0].axvline(x=0.99, color='r', linestyle='--', label='ëª©í‘œ (99%)')
        axes[1, 0].set_title("ë”¥ëŸ¬ë‹ OCR ì •í™•ë„ ë¶„í¬")
        axes[1, 0].set_xlabel("ì •í™•ë„")
        axes[1, 0].set_ylabel("ë¹ˆë„")
        axes[1, 0].legend()
        
        # 4. ì •í™•ë„ vs ì²˜ë¦¬ ì‹œê°„
        axes[1, 1].scatter(df["dl_time"], df["dl_accuracy"])
        axes[1, 1].set_title("ì •í™•ë„ vs ì²˜ë¦¬ ì‹œê°„")
        axes[1, 1].set_xlabel("ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)")
        axes[1, 1].set_ylabel("ì •í™•ë„")
        
        plt.tight_layout()
        
        # ê·¸ë˜í”„ ì €ì¥
        output_path = "./reports/benchmark_visualization.png"
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        plt.savefig(output_path, dpi=300)
        logger.info(f"ì‹œê°í™” ì €ì¥ ì™„ë£Œ: {output_path}")
        
        # CSVë¡œ ê²°ê³¼ ì €ì¥
        csv_path = "./reports/benchmark_results.csv"
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        logger.info(f"ê²°ê³¼ CSV ì €ì¥ ì™„ë£Œ: {csv_path}")


class TestKoreanOCR(unittest.TestCase):
    """í•œêµ­ì–´ OCR ìœ ë‹› í…ŒìŠ¤íŠ¸"""
    
    @classmethod
    def setUpClass(cls):
        """í…ŒìŠ¤íŠ¸ ì‹œì‘ ì „ ì„¤ì •"""
        cls.ocr_engine = UltraKoreanOCR(OCRConfig())
        cls.deep_enhancer = DeepLearningOCREnhancer()
        cls.layout_analyzer = SchoolRecordLayoutAnalyzer()
    
    def test_korean_text_recognition(self):
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì‹ í…ŒìŠ¤íŠ¸"""
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        test_text = "ì•ˆë…•í•˜ì„¸ìš” í•œêµ­ì–´ OCR í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤"
        image = self._create_test_image(test_text)
        
        # OCR ìˆ˜í–‰
        result = self.ocr_engine.process_image("./temp_test.jpg")
        
        # ê²°ê³¼ í™•ì¸
        self.assertIsNotNone(result)
        self.assertIn("full_text", result)
        
        # ì •í™•ë„ í™•ì¸
        accuracy = self._calculate_accuracy(result["full_text"], test_text)
        self.assertGreater(accuracy, 0.8)  # 80% ì´ìƒ ì •í™•ë„
    
    def test_image_preprocessing(self):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        # ë…¸ì´ì¦ˆê°€ ìˆëŠ” ì´ë¯¸ì§€ ìƒì„±
        image = np.random.randint(0, 255, (100, 300, 3), dtype=np.uint8)
        
        # ì „ì²˜ë¦¬ ìˆ˜í–‰
        preprocessor = self.ocr_engine.preprocessor
        enhanced = preprocessor.enhance_image(image)
        
        # ê²°ê³¼ í™•ì¸
        self.assertIsNotNone(enhanced)
        self.assertEqual(enhanced.shape[:2], image.shape[:2])
    
    def test_layout_analysis(self):
        """ë ˆì´ì•„ì›ƒ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± (í…Œì´ë¸” í¬í•¨)
        image = np.ones((500, 500, 3), dtype=np.uint8) * 255
        cv2.rectangle(image, (50, 50), (450, 450), (0, 0, 0), 2)
        cv2.line(image, (50, 150), (450, 150), (0, 0, 0), 2)
        cv2.line(image, (200, 50), (200, 450), (0, 0, 0), 2)
        
        # ë ˆì´ì•„ì›ƒ ë¶„ì„
        result = self.layout_analyzer.analyze_layout(image)
        
        # ê²°ê³¼ í™•ì¸
        self.assertIsNotNone(result)
        self.assertIn("layout_elements", result)
        self.assertIn("statistics", result)
    
    def test_field_extraction(self):
        """í•„ë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
        # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
        test_text = "í•™ë…„: 2í•™ë…„ ë°˜: 3ë°˜ ë²ˆí˜¸: 15ë²ˆ ì´ë¦„: í™ê¸¸ë™"
        
        # OCR ê²°ê³¼ ì‹œë®¬ë ˆì´ì…˜
        ocr_result = {"full_text": test_text}
        
        # í•„ë“œ ì¶”ì¶œ
        fields = self.ocr_engine.extract_school_record_fields(ocr_result)
        
        # ê²°ê³¼ í™•ì¸
        self.assertEqual(fields["í•™ë…„"], "2")
        self.assertEqual(fields["ë°˜"], "3")
        self.assertEqual(fields["ë²ˆí˜¸"], "15")
        self.assertEqual(fields["ì´ë¦„"], "í™ê¸¸ë™")
    
    def test_spell_checking(self):
        """ë§ì¶¤ë²• ê²€ì‚¬ í…ŒìŠ¤íŠ¸"""
        # ì˜¤ë¥˜ê°€ ìˆëŠ” í…ìŠ¤íŠ¸
        text_with_errors = "í•™ìƒì€ ì„±ì‹£í•˜ê³  ì±…ì„ê°ì´ ê°•í•¨ë‹ˆë‹¤"
        
        # ë§ì¶¤ë²• ê²€ì‚¬
        checker = self.deep_enhancer.spell_checker
        corrected, corrections = checker.check_and_correct(text_with_errors)
        
        # ê²°ê³¼ í™•ì¸
        self.assertNotEqual(corrected, text_with_errors)
        self.assertGreater(len(corrections), 0)
    
    def test_performance(self):
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        image = self._create_test_image("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ìš© í•œê¸€ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤")
        
        # ì‹œê°„ ì¸¡ì •
        start_time = time.time()
        result = self.ocr_engine.process_image("./temp_test.jpg")
        elapsed_time = time.time() - start_time
        
        # ì„±ëŠ¥ í™•ì¸
        self.assertLess(elapsed_time, 5.0)  # 5ì´ˆ ì´ë‚´ ì²˜ë¦¬
        self.assertGreater(result.get("average_confidence", 0), 0.8)  # 80% ì´ìƒ ì‹ ë¢°ë„
    
    def _create_test_image(self, text: str) -> np.ndarray:
        """í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ìƒì„±"""
        image = np.ones((100, 600, 3), dtype=np.uint8) * 255
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(image, text, (10, 50), font, 0.7, (0, 0, 0), 2)
        cv2.imwrite("./temp_test.jpg", image)
        return image
    
    def _calculate_accuracy(self, predicted: str, ground_truth: str) -> float:
        """ì •í™•ë„ ê³„ì‚°"""
        if not ground_truth:
            return 0.0
        
        correct = sum(1 for p, g in zip(predicted, ground_truth) if p == g)
        return correct / len(ground_truth)
    
    @classmethod
    def tearDownClass(cls):
        """í…ŒìŠ¤íŠ¸ ì¢…ë£Œ í›„ ì •ë¦¬"""
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists("./temp_test.jpg"):
            os.remove("./temp_test.jpg")


if __name__ == "__main__":
    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    logger.info("Starting Korean OCR Benchmark System...")
    
    benchmark = OCRBenchmark()
    results = benchmark.run_comprehensive_benchmark("./test_data")
    
    # ìœ ë‹› í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    logger.info("\nRunning unit tests...")
    unittest.main(argv=[''], exit=False)